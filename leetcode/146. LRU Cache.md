# 146. LRU Cache

Design and implement a data structure for [Least Recently Used (LRU) cache](https://en.wikipedia.org/wiki/Cache_replacement_policies#LRU). It should support the following operations: `get` and `put`.

`get(key)` - Get the value (will always be positive) of the key if the key exists in the cache, otherwise return -1.
`put(key, value)` - Set or insert the value if the key is not already present. When the cache reached its capacity, it should invalidate the least recently used item before inserting a new item.

The cache is initialized with a **positive** capacity.

**Follow up:**
Could you do both operations in **O(1)** time complexity?

**Example:**

```
LRUCache cache = new LRUCache( 2 /* capacity */ );

cache.put(1, 1);
cache.put(2, 2);
cache.get(1);       // returns 1
cache.put(3, 3);    // evicts key 2
cache.get(2);       // returns -1 (not found)
cache.put(4, 4);    // evicts key 1
cache.get(1);       // returns -1 (not found)
cache.get(3);       // returns 3
cache.get(4);       // returns 4
```



# Solution

We need a dictionary-like data structure to keep track of the order of the insertion.

```collections.OrderedDict``` in python is a naturally suitable collection.

* .popitem(False) will pop the least last inserted item
* .move_to_end(key) will move key as if the key was last added

```python
class LRUCache:
    
    def __init__(self, capacity: int):
        self.capacity = capacity
        self.da = collections.OrderedDict()
        
    def get(self, key):
        if key not in self.da:
            return -1
        t = self.da[key]
        self.da.move_to_end(key)
        return t
    
    def put(self, key, value):
        
        if key in self.da:
            self.da[key] = value
            self.da.move_to_end(key)
        else:
            self.da[key] = value
            if len(self.da) > self.capacity:
                self.da.popitem(False)# this can be replaced with del da[next(iter(da))]

```



* OrderedDict is implemented by double-linked-list and hashtable, so we can do LRUCache by this
* the idea is the following



```python
class Node:
    def __init__(self, key, val):
        self.val = val
        self.before = None
        self.next = None
        self.key = key

class LRUCache:
    def __init__(self, capacity: int):
        # the most recent is put on the head
        self.capacity = capacity
        self.da = {}
        self.length = 0
        self.head = None
        self.end = None
        
    def get(self, key):
        if key not in self.da:
            return -1
        n = self.da[key]
        self._del(n)
        self._add(n)
        return n.val
    
    def put(self, key, value):
        
        if key in self.da:
            old = self.da[key]
            self._del(old)
            old.val = value
            old.next = None
            old.before = None
            self._add(old)
        else:
            new = Node(key, value) 
            self.da[key] = new
            self._add(new)
            if len(self.da) > self.capacity:
                k = self._pop()
                del self.da[k]

    
    def _del(self,n):
        if n.before:
            n.before.next = n.next
        else:
            self.head = n.next
        if n.next:
            n.next.before = n.before
        else:
            self.end = n.before
        n.next = None
        n.before = None

    
    def _add(self,n):
        if not self.head:
            self.head = n
            self.end = n
        else:
            n.next = self.head
            self.head.before = n
            self.head = n

    def _pop(self):
        res = self.end.key
        self.end = self.end.before
        self.end.next = None
        if not self.end:
            self.head = self.end
        return res

```

